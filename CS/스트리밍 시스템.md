## 스트리밍 데이터??
스트리밍 데이터는 짧은 대기 시간으로 처리하는 것을 목표로, 계속해서 증분하는 방식으로 내보내지는 대용량 데이터입니다. 조직은 보통 몇 바이트부터 메가바이트(MB)에 이르는 다양한 크기의 메시지, 레코드 또는 데이터를 동시에 내보내는 수천 개의 데이터 소스를 보유합니다. 스트리밍 데이터에는 기업이 자사 비즈니스의 여러 측면에 대한 실시간 분석을 수행하고 가시성을 얻기 위해 사용하는 위치, 이벤트, 센서 데이터가 포함됩니다. 예를 들어 기업이 클릭스트림 분석과 소셜 미디어 스트림의 고객 게시물을 지속적으로 분석하여 자사 브랜드와 제품에 대한 여론 변화를 추적하고, 필요에 따라 즉각 반응할 수 있습니다.
## 스트리밍 데이터의 특징에는 어떤 것들이 있나요?
데이터 스트림은 다음과 같은 구체적인 특성에 따라 정의됩니다.

시간순 중요성
데이터 스트림의 각 요소에는 타임 스탬프가 포함됩니다. 데이터 스트림 자체가 시간에 민감할 수 있지만, 특정 기간 이후에는 그 중요성이 감소될 수 있습니다. 예를 들어 사용자의 현재 위치에 기반하여 식당 추천을 생성하는 애플리케이션을 가정해 볼 수 있습니다. 사용자의 실시간 지리적 위치 데이터에 따라 반응하지 않으면 데이터는 중요성을 상실합니다.

지속적 흐름
데이터 스트림에는 시작도 끝도 없습니다. 요구되는 만큼 데이터를 끊임없이 지속적으로 수집합니다. 예를 들어 서버 활동 로그는 서버가 실행되는 동안 계속 누적됩니다.

고유성
데이터 스트림 전송을 반복하는 것은 시간적 민감성 때문에 쉽지 않은 일입니다. 따라서 정확한 실시간 데이터 처리가 중요합니다. 안타깝게도 재전송에 대한 프로비저닝은 대부분의 스트리밍 데이터 소스에서 제한됩니다.

비균질성
일부 소스는 문자열, 숫자, 날짜, 이진(Binary) 유형을 포함하는 데이터 유형을 JSON, Avro, 쉼표로 구분된 값(CSV) 등 여러 가지 구조화된 형식으로 스트리밍할 수 있습니다. 스트림 처리 시스템에는 이러한 데이터 변형을 처리할 수 있는 기능이 있어야 합니다.

불완전성
소스의 일시적인 오류는 스트리밍된 데이터 내의 요소에 손상 또는 누락을 유발할 수 있습니다. 스트림의 지속성이라는 특징 때문에 데이터 일관성을 보장하기가 어려울 수 있습니다. 스트림 처리 및 분석 시스템은 이러한 오류를 완화 또는 최소화하기 위해 일반적으로 데이터 검증 로직을 포함합니다.

## 스트리밍 데이터가 중요한 이유는 무엇인가요?
기존의 데이터 처리 시스템은 중앙 데이터 웨어하우스에서 데이터를 캡처하여 이를 그룹 또는 배치 단위로 처리합니다. 이러한 시스템은 분석 전에 데이터를 수집하고 구조화하도록 구축되었습니다. 그러나 최근 몇 년에 걸쳐 기업 데이터의 성격과 기본 데이터 처리 시스템이 크게 변화했습니다.

무한한 데이터 볼륨
스트림 소스로부터 생성된 데이터 볼륨은 굉장히 크기 마련이고, 이에 따라 스트리밍 데이터의 무결성(검증), 구조(진화) 또는 속도(스루풋 및 지연 시간)을 규제하기 위한 실시간 분석이 까다로운 과제가 됩니다.

고급 데이터 처리 시스템
그와 동시에, 클라우드 인프라는 컴퓨팅 리소스의 확장과 사용량에 있어 유연성을 도입했습니다. 정확히 필요한 만큼만 사용하고 사용한 만큼에 대해서만 비용을 지불하면 됩니다. 스트리밍 데이터 저장 전후 언제라도 실시간 필터링 또는 집계 옵션을 이용할 수 있습니다. 스트리밍 데이터 아키텍처는 클라우드 기술을 사용하여 스트리밍 데이터를 필요한 만큼 소비, 강화, 분석 및 영구 저장합니다.